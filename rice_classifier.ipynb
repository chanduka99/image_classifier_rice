{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0d35b1",
   "metadata": {},
   "source": [
    "### **1. Setup and load data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b9963",
   "metadata": {},
   "source": [
    "##### **1.1 Install dependencies and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21355fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os #used for handling file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebae20f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') #verify tensorflow is using the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db97ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors. Setting GPU memory growth limit #### if this approach still doesn't resolve the memory consumption issue. we need to reduce size of the mini batches when training\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f4c2b",
   "metadata": {},
   "source": [
    "#### **1.2 Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fb11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: E:\\AKILA\\RiceClassifcation\n"
     ]
    }
   ],
   "source": [
    "# # # Change working directory to notebook location# \n",
    "# notebook_path = r\"E:\\AKILA\\RiceClassifcation\"# \n",
    "# os.chdir(notebook_path# )\n",
    "# print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2i\n",
    "\n",
    "# data_dir = \"Data\"\n",
    "# data_dir_pat h = s.path.join(cwd, data_dirf)\n",
    "# o.litdi()r(data_di:r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39a895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"Data\"\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = (254,254)\n",
    "ROOT_PATTERN = f\"{DATA_DIR}/*/*/*.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa9630cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset of file paths\n",
    "paths = tf.data.Dataset.list_files(file_pattern=ROOT_PATTERN,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a529de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label vocabularies\n",
    "\n",
    "\n",
    "type_dirs = tf.io.gfile.listdir(DATA_DIR)\n",
    "# filter, to only keep dir names\n",
    "image_class_type_dirs = []  # will contain ['AT 362', 'BG 357', 'BG 360', 'BW 367',......]\n",
    "for dir in type_dirs:\n",
    "    if tf.io.gfile.isdir(os.path.join(DATA_DIR,dir)):\n",
    "        image_class_type_dirs.append(dir)\n",
    "\n",
    "\n",
    "# quality_dirs = tf.io.gfile.listdir(os.path.join(DATA_DIR,image_class_type_dirs[0]))\n",
    "# filter, to only keep dir names\n",
    "# image_class_quality_dirs = [] # will contain ['Bad', 'Good']\n",
    "# for dir in quality_dirs:\n",
    "#     if tf.io.gfile.isdir(os.path.join(DATA_DIR,image_class_type_dirs[0],dir)):\n",
    "#         image_class_quality_dirs.append(dir)\n",
    "image_class_quality_dirs = ['Bad', 'Good']\n",
    "\n",
    "image_class_type_table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(image_class_type_dirs),\n",
    "        values=tf.constant(list(range(len(image_class_type_dirs))))\n",
    "        ),\n",
    "    default_value=-1\n",
    ")\n",
    "\n",
    "image_class_quality_table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(image_class_quality_dirs),\n",
    "        values=tf.constant(list(range(len(image_class_quality_dirs))))\n",
    "    ),\n",
    "    default_value=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b49149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract type and quality label \n",
    "def parse_label(path):\n",
    "    # path format should be Data\\\\Type\\\\Quality\\\\Image.JPG\n",
    "    # path_string = path.decode('utf-8')\n",
    "    # parts = path_string.split(\"\\\\\")\n",
    "    parts = tf.strings.split(\"/\")\n",
    "    rice_type = parts[-3]\n",
    "    rice_quality = parts[-2]\n",
    "\n",
    "    # t = image_class_type_table.lookup(tf.constant(rice_type))\n",
    "    t = image_class_type_table.lookup(rice_type)\n",
    "    # q = image_class_quality_table.lookup(tf.constant(rice_quality))\n",
    "    q = image_class_quality_table.lookup(rice_quality)\n",
    "    return t, q\n",
    "\n",
    "# helper function to load and preprocess image\n",
    "def load_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])  # Set shape before resize\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# act as the lambda function for the mapping\n",
    "def load_item(path):\n",
    "    t, q = parse_label(path)\n",
    "    image = load_image(path)\n",
    "    return image, {\"type\": t, \"quality\": q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fcfcdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = paths.shuffle(100)\n",
    "# dataset = dataset.map(loadItem,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataset = (\n",
    "    paths\n",
    "    .shuffle(100)\n",
    "    .map(load_item, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_riceClassification",
   "language": "python",
   "name": "venv_riceclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
